# 字节序

字节序，又称端序或尾序（Endianness），在计算机领域中，指电脑内存中或在数字通讯链路中，占用多少个字节的数据的字节排列顺序。<br/>

几乎在所有平台上，多字节对象都被存储为连续字节序列。例如：<br/>
一个字节最大可以存储 255，那么 256 就需要两个字节来存储了。用 16 进制来表示就是 0x0100（256）这时候，可以发现，高字节部分就是 01，低字节部分则是 00。<br/>

在计算机存储中，内存也被区分为低位地址到高位地址，这样就区分出了两种情况来存储数据的高字节和低字节部分：<br/>

- 大端序，将数据的**高位字节**存在内存的低位地址中。
- 小端序，将数据的**低位字节**存在内存的低位地址中。

```

           高——>低
    数据：0x12345678

    大端序              小端序

    0x01 —— 12         0x01 —— 78
    0x02 —— 34         0x02 —— 56
    0x03 —— 56         0x03 —— 34
    0x04 —— 78         0x04 —— 12

```

## 为何要有字节序

根据计算机电路来看会内存中会从低地址开始处理，效率比较高。但是由于数据不管先访问高字节数据还是低字节数据应该也没什么区别（先高字节，即大端序便于理解），同时也由于各个厂商的不同，Intel、AMD...不同的厂商也推出了各种不同的字节序，主机字节序也多了不确定性。出现网络通讯以后，为了解决这个不统一的问题，TCP/IP，RFC1700 规定使用“大端序”作为网络字节序。所以不管主机字节序是什么，都应该转换为网络字节序才能进行数据传输。

> 为了方便提供了转换函数供程序员使用：

    主机字节序转网络：htons（16位）、htonl（32位）
    网络字节序转主机：ntons（16位）、ntonl（32位）



```C++
//判断大小端序
#include <stdio.h>

int main(){
    unsigned int x = 0x12345678;
    // 获取x的地址，取一个字节
    char* c = (char*)&x;

    // c指向x的第一块地址，通过判断第一块地址里的数据从而可以推出大小端序
    if(*c == 0x78){

        // 低地址存低字节数据
        printf("小端序");
    }else{

        // 低地址存高字节数据
        printf("大端序");
    }
}

```


## 身边的字节序
字符编码方式UTF-16，UTF-32同样面临字节序的问题，因为他们分别使用2个字节和4个字节编码Unicode字符，一旦某个值由多个字节表示，就必须要考虑到存储顺序的问题了。于是，采用了最简单粗暴的方式，给这个文件头部多写几个字符，用来表示大端序还是小端序。

```

    BOM|头部的字符           编码                      端序
    FF FE               UTF-16/UCS-2                Little endian
    FE FF               UTF-16/UCS-2                Big endian
    FF FE 00 00         UTF-32/UCS-4                Little endian
    00 00 FE FF         UTF-32/UCS-4                Big endian

```
上述的都是多字节编码，为什么没有提到常见的UTF-8呢，因为UTF-8是单字节编码的，也就是说从一开始就不会出现端序问题。但是微软为了统一UTF-X的操作，就硬给UTF-8加了BOM，内容为EF BB BF。
这样的话，在Windows下写Shell脚本，就会出现无法识别的问题:
shell会去找以#!/usr/bin/env bash的编码，而UTF-8却以EF BB BF开头。所以有BOM的话shell解释器就报错了。

/>

- CPU 必须至少有两种状态：操作系统状态和应用程序状态，不同状态下，相同的指令会产生不同的结果，也就保证某些任务只有操作系统能执行，某些只有应用程序能执行。
- 操作系统必须要有办法配合 CPU，设置哪些内存可访问，哪些内存不能访问（或者说只有操作系统状态下能访问），不能访问的包括操作系统自己的代码区和数据区，中断向量表等。
- CPU 在触发中断时需要自动切换到操作系统状态（否则无法进行多任务切换）。
- 操作系统状态可以自由切换应用程序状态，应用程序状态不能任意切换到操作系统状态，但也需要有触发进入操作系统代码并切换到操作系统状态的能力（否则无法调用操作系统功能）。

## 从 CPU 设计上谈内核态与用户态

回到实际 CPU 的设计上，显然 CPU 的设计者思路是和我们差不多的，这里我们叫做操作系统状态的，在实际概念中就叫做内核态，在 CPU 设计上则叫做特权模式；我们呢叫做应用程序状态的，在实际概念中叫做用户态，CPU 设计上叫做用户模式。

注意，内核态并不是一个东西，不是一块区域，没有处于什么地方的一说，它是 CPU 的两种状态之一。如果不是说进入内核态，而是说切换到内核态，可能就没有这种误解了。都怪 intel 将系统调用的指令起名叫 sysenter，所以大家都比较习惯说“进入”内核态。实际上 CPU 可能被细分为更多的运行模式，不过操作系统至少需要这两种，有时特权和用户模式指的并不是一种真正的模式，而是一类模式，比如好几种类似，但却也有区别的运行模式都合成特权模式。

> 在 CPU 的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清理内存、设置时钟等。如果允许所有的程序都可以使用这些指令，那么系统崩溃的概率将大大增加。<br/>

    CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及相关模块使用，普通应用程序只能使用那些不会造成灾难的指令。比如Intel的CPU将权限分为四个等级：Ring0~Ring3<br/>
    其实Linux系统只使用了Ring0和Ring3两个运行等级（Windows也一样）。当进程运行在Ring3级别时被称为运行在用户态，而运行在Ring0级别时被称为运行在内核态。<br/>

### 内存的内核态与用户态

内核访问限制，这也是这个设计中最困难的一部分。相比之下，在用户模式下禁用一部分指令功能比较简单，无非是控制器里加入相应的组合逻辑，而内存读写则不一样，指令是相同的，只是访问的内存地址不同，这时候有些地址是可以访问的，有些地址则不能访问，能不能访问的区别仅仅在内存地址上。要知道，CPU 是支持利用寄存器间接寻址的，因此这个非法的指令不可能在译码的阶段就发现，而是必须在执行期间发现，同时，哪些地址可以访问，哪些地址不能访问你，必须完全是可配置的，操作系统有极大的自由。最后，这个系统还必须对应用程序有最基础的友好性，不能让应用程序太难写。

既然内存里每个单元是否允许访问都需要能够设置，而内存的大小是不确定的，那这个设置的数量也不确定，而且会比较庞大，大寸土寸金的 CPU 里放这么多、这么复杂的设置是很不合适的。唯一可行的方案就是通过内存自己来管理内存——使用一部分内存来存储其他内存应该如何使用的配置。这样实际访问内存时就需要：**先访问内存中的内存配置，根据内存配置判断要访问的内存是否允许访问，如果不允许访问现需要触发非法操作的中断，而如果允许访问则正常访问；同时，内存中的内存配置也会收到内存中的内存配置的管理（自我调整 ？）**

CPU 中引入了一种称为 MMU 的单元，它可能现在 CPU 最复杂的组件之一了。它能从内存中以指定格式加载配置，从而影响用户模式下访问内存的特性。为了方便进程切换，这个格式往往有复杂的数据结构 ，还要支持多种多样的配置功能。在用户模式下，所有内存访问经过 MMU，从而对内存的访问受到了保护；_在特权模式下，内存访问绕过 MMU，直接访问物理内存，从而获得完整的权限_,**_争议：Linux 在打开 MMU 以后，内存访问始终都通过 MMU。同时内核对自身使用的物理地址空间页设置了页表项，页表项上有字段指明了访问所需的 CPU 模式，这样 MMU 就可以拒绝用户态程序的访问了_**。

从具体设计上来说最直接的想法就是用户模式和特权模式都使用相同的内存地址，只是在用户模式下设置哪些内存可以访问，哪些不能访问。这种访问是可行的，但是还有一些缺陷：

- 在保护模式出现之前，编译器都是针对实模式设计的，在编译过程中，使用哪些内存地址范围，内存的什么位置放什么数据，都完全是编译器可以自己决定的。即使是保护模式出现之后，操作系统的部分也需要相同的编译方式。如果应用程序的编译需要放弃这一套逻辑，改成所有的地址都由操作系统分配，那现有的汇编程序和编译器都需要重写，这个代价难以接受。
- 应用程序经常会需要使用一大片连续的内存空间，比如说设计数组的一系列算法如果的内存空间全部都是动态分配的,那有些程序可能会不断的申请小块小块的空间，从而让内存空间碎片化，没有连续成品的内存。等这些程序退出之后,释放出来的内存都是小块、不连续的，操作相同就没法让其他应用程序使用连续成片的内存了。
- 安全上有隐患，虽然应用程序没法读取其他内存，但是应用程序可以知道哪些内存以及被其他应用程序用了，于是可以从内存地址的分配上分析出一些信息，例如当前操作系统可能执行了哪些其他应用程序，这些应用程序可能处于什么状态等等。还有可能因为 CPU 实现的 BUG 导致应用程序能以意想不到的方式读取到不应当能读取的数据。
- 现代操作系统希望支持一些高级的内存管理方式，例如虚拟内存——将一部分不使用的内存暂时放在磁盘上，这样可以用较少的内存支撑更多的应用程序；写时赋值——两个应用程序使用相同的内存块，希望能暂时使用同一个物理内存，但是其中的一个需要修改的时候再将它复制成两份独立的内存块，从而节约内存。

现代 MMU 通常使用**虚拟地址空间**的技术来解决这个问题，也就是所谓的“用户空间”。在用户模式下，所有访问内存的地址都是虚拟地址，它与实际的物理地址是对应不上的。这样，即便有两个应用程序使用的相同的地址，他们也可以做到互不干扰，只需要通过技术手段让他们实际映射到不同的物理地址就行了。MMU 和操作系统统称作页表的数据结构来实现虚拟地址到物理地址的映射，一般来说在 x86-64 系统中，内存按照 4kb 的大小分成页，每个地址对齐的页可以独立从任意一个虚拟地址段，两个起始地址的低 12 位都是 0（也就是所谓的地址对其，这样任意一个虚拟地址映射到物理地址时，最低 12 位不需要动）。页表的结构在每次进入用户模式之前都可以重新设置，这样切换基础之后，页表发生了变化，统一规格虚拟地址就会映射到不同的物理地址上，这就同时实现了多个目标：

- 应用程序有独立的虚拟地址空间
- 应用程序只能访问已经映射了的虚拟地址空间，未映射的物理地址无法访问（实现了保护内存）
- 页表和中断向量表，理所当然不会被映射出来
- 部分 RISC（x86 是 CISC）的架构上，内存和外部设别有统一的地址空间，不映射外设的地址，也就阻止了对外设的访问
- 应用程序看来连续的内存，在物理内存上不需要是连续的，内存使用的效率很高
- 以某些方式访问某些页面是可以触发操作系统的中断，操作系统可以趁这个机会修改页表，这就给操作系统实现高级内存管理功能打下了基础

### 用户空间进入内核空间

其实所有的系统资源管理都是在内核空间中完成的，比如读写磁盘文件、分配回收内存、从网络接口读写数据等等。我们应用此程序是无法直接进行这些操作的，但是我们可以通过（操作系统对内核提供的接口）内核提供的接口来完成这样的任务。
比如应用程序要读取磁盘上的一个文件，它可以向内核发起一个“系统调用”告诉内核：“我要读取磁盘上的某某文件”。其实就是通过一个特殊的指令让进程从用户态切换到了内核态（即允许访问内核空间），在内核空间中，CPU 可以执行任何的指令，当然也包括从磁盘上读取数据，具体过程就是把数据读取到内核空间中，然后再把数据拷贝到用户空间并从内核态切换到用户态，此时应用程序已经从系统调用中返回并且拿到了想要的数据。
简单来说就是应用程序把*从磁盘读取文件*外包给了系统内核。

对于一个进程来讲，从用户空间进入内核空间并最终返回到用户空间，这个过程是十分复杂的。举个例子，比如我们经常接触的概念 "堆栈"，其实进程在内核态和用户态各有一个堆栈。运行在用户空间时进程使用的是用户空间中的堆栈，而运行在内核空间时，进程使用的是内核空间中的堆栈。所以说，Linux 中每个进程有两个栈，分别用于用户态和内核态。其中虚拟地址就说此堆栈的实现，内核态和用户态都享有各自的页表，在 CPU 的不同状态下访问不同的页表，如此便是区分。

用户态的进程必须切换到内核态才能使用系统的资源，概括的说，有三种方式可以从用户态切换到内核态：系统调用、软件中断、硬件中断。

## 外部设备

用户模式下的应用程序无法直接访问硬件设备，但如果完全没法利用硬件设备，那就太不方便了。这两者的权衡是，应用程序通过操作系统使用硬件，也就是说应用程序给操作系统发起请求，操作系统处理请求时将请求转发到硬件，硬件响应后，再将请求转发回应用程序。

许多硬件使用中断和 DMA 来传输信号或数据，这种情况下，操作系统开始操作后，到硬件操作完成前会有一段空闲时间，这时候操作系统可以将当前应用程序挂起，先去执行其他应用程序。当硬件操作完成时，会触发中断，中断向量表在内存中，是操作系统提前设置好的，指向了操作系统自己的代码；同时，这个中断也会立即强迫 CPU 进入特权模式，这时候操作系统就有机会来处理硬件返回的数据，同时根据进程优先级，可以将之前挂起的进程重新切换回来重新开始继续执行。

不同的硬件往往有不同的接口，但操作系统会希望给应用程序统一的接口，这中间就涉及到驱动适配的问题，厂家的驱动程序可以将通用的请求转化未自己家硬件能识别的请求格式。

## WindowsPE

保护模式不意味着应用程序访问硬件的额能力变弱了，实际上，应用程序访问硬件的能力完全取决于操作系统是否允许。别说是 WindowsPE，实际上任意版本的 Windows 都可以允许一个最高权限用户程序直接读写物理硬盘的（通过 CreateFileEx 的 WindowsAPI 就可以，就跟打开一个普通文件一样），唯一的问题在于 Windows 依赖很多磁盘文件，如果在普通 Windows 执行过程中格式化系统盘，操作系统会崩溃，而 WindowsPE 比较小，可以将重要的东西都整个加载到内存里，就可以在保持操作系统正常工作的情况下格式化硬盘了。

## ISSUE

那么操作系统是如何知道某个进程是内核还是用户？是通过进程 id 区分的？另外，内存访问限制这块也是，一直有听说内核态和用户态所处的内存位置是不同的，难道是通过内存所在位置吗？这样子的话，也不安全？因为用户态可以通过比如位置偏移找到内核态的地址区，然后就能拿到高权限了？
还有就是用户态切换到内核态，经常听说开销很大什么的，但是这个切换，本质上不是 cpu 上进程切换吗？cpu 对用户态的进程调度，也是无时无刻不在发生的，那为什么经常会看到“减少内核态切换以提高性能”的说法？

> 一个一个说，区分进程自然主要是靠进程 id 以及相关的数据结构。

    内存相关的我解释过MMU的作用，启用MMU之后，无论通过CPU指令访问哪个地址、加不加偏移，访问的都是虚拟地址，虚拟地址只有经过MMU映射才能对应到相应物理地址，这个对应是按页进行的，只有明确指定的页才有对应，不指定的页无论如何都是访问不到的。操作系统内核在切换到用户进程的时候会修改MMU的配置，让映射的页发生变化，这样用户进程就没法访问内核的内存了。
    进程切换并不是CPU完成的，CPU只按时触发一个终断来调用操作系统功能，具体的切换是靠操作系统自己完成的，涉及很多保存现场、决定接下来调度到哪个进程、恢复现场这样的操作。

# 交互

## 用户级程序主动发起的信息交互

### A 编写自己的系统调用

    系统调用是用户级程序访问内核最基本的方法。目前linux大致提供了二百多个标准的系统调用（参见内核代码树中的include/ asm-i386/unistd.h和arch/i386/kernel/entry.S文件），并且允许我们添加自己的系统调用来实现和内核的信息交换。比如我们希望建立一个系统调用日志系统，将所有的系统调用动作记录下来，以便进行入侵检测。此时，我们可以编写一个内核服务程序。该程序负责收集所有的系统调用请求，并将这些调用信息记录到在内核中自建的缓冲里。我们无法在内核里实现复杂的入侵检测程序，因此必须将该缓冲里的记录提取到用户空间。最直截了当的方法是自己编写一个新系统调用实现这种提取缓冲数据的功能。当内核服务程序和新系统调用都实现后，我们就可以在用户空间里编写用户程序进行入侵检测任务了，入侵检测程序可以定时、轮训或在需要的时候调用新系统调用从内核提取数据，然后进行入侵检测了。

### B 编写驱动程序

    Linux/UNIX的一个特点就是把所有的东西都看作是文件(every thing is a file)。系统定义了简洁完善的驱动程序界面，客户程序可以用统一的方法透过这个界面和内核驱动程序交互。而大部分系统的使用者和开发者已经非常熟悉这种界面以及相应的开发流程了。

驱动程序运行于内核空间，用户空间的应用程序通过文件系统中/dev/目录下的一个文件来和它交互。这就是我们熟悉的那个文件操作流程：open() —— read() —— write() —— ioctl() —— close()。（需要注意的是也不是所有的内核驱动程序都是这个界面，网络驱动程序和各种协议栈的使用就不大一致，比如说套接口编程虽然也有 open()close()等概念，但它的内核实现以及外部使用方式都和普通驱动程序有很大差异。）

设备驱动程序在内核中要做的中断响应、设备管理、数据处理等等各种工作这篇文章不去关心，我们把注意力集中在它与用户级程序交互这一部分。操作系统为此定义了一种统一的交互界面，就是前面所说的 open(), read(), write(), ioctl()和 close()等等。每个驱动程序按照自己的需要做独立实现，把自己提供的功能和服务隐藏在这个统一界面下。客户级程序选择需要的驱动程序或服务（其实就是选择/dev/目录下的文件），按照上述界面和文件操作流程，就可以跟内核中的驱动交互了。其实用面向对象的概念会更容易解释，系统定义了一个抽象的界面（abstract interface），每个具体的驱动程序都是这个界面的实现（implementation）。

所以驱动程序也是用户空间和内核信息交互的重要方式之一。其实 ioctl, read, write 本质上讲也是通过系统调用去完成的，只是这些调用已被内核进行了标准封装，统一定义。因此用户不必向填加新系统调用那样必须修改内核代码，重新编译新内核，使用虚拟设备只需要通过模块方法将新的虚拟设备安装到内核中（insmod 上）就能方便使用。关于此方面设计细节请查阅参考资料 5，编程细节请查阅参考资料 6。

在 linux 中，设备大致可分为：字符设备，块设备，和网络接口（字符设备包括那些必须以顺序方式，像字节流一样被访问的设备；如字符终端，串口等。块设备是指那些可以用随机方式，以整块数据为单位来访问的设备，如硬盘等；网络接口，就指通常网卡和协议栈等复杂的网络输入输出服务）。如果将我们的系统调用日志系统用字符型驱动程序的方式实现，也是一件轻松惬意地工作。我们可以将内核中收集和记录信息的那一部分编写成一个字符设备驱动程序。虽然没有实际对应的物理设备，但这并没什么问题：Linux 的设备驱动程序本来就是一个软件抽象，它可以结合硬件提供服务，也完全可以作为纯软件提供服务（当然，内存的使用我们是无法避免的）。在驱动程序中，我们可以用 open 来启动服务，用 read()返回处理好的记录，用 ioctl()设置记录格式等，用 close()停止服务，write()没有用到，那么我们可以不去实现它。然后在/dev/目录下建立一个设备文件对应我们新加入内核的系统调用日志系统驱动程序。

### C: 使用 proc 文件系统

    proc是Linux提供的一种特殊的文件系统，推出它的目的就是提供一种便捷的用户和内核间的交互方式。它以文件系统作为使用界面，使应用程序可以以文件操作的方式安全、方便的获取系统当前运行的状态和其它一些内核数据信息。

proc 文件系统多用于监视、管理和调试系统，我们使用的很多管理工具如 ps,top 等，都是利用 proc 来读取内核信息的。除了读取内核信息，proc 文件系统还提供了写入功能。所以我们也就可以利用它来向内核输入信息。比如，通过修改 proc 文件系统下的系统参数配置文件（/proc/sys），我们可以直接在运行时动态更改内核参数；再如，通过下面这条指令：

echo 1 > /proc/sys/net/ip_v4/ip_forward

开启内核中控制 IP 转发的开关，我们就可以让运行中的 Linux 系统启用路由功能。类似的，还有许多内核选项可以直接通过 proc 文件系统进行查询和调整。

除了系统已经提供的文件条目，proc 还为我们留有接口，允许我们在内核中创建新的条目从而与用户程序共享信息数据。比如，我们可以为系统调用日志程序（不管是作为驱动程序也好，还是作为单纯的内核模块也好）在 proc 文件系统中创建新的文件条目，在此条目中显示系统调用的使用次数，每个单独系统调用的使用频率等等。我们也可以增加另外的条目，用于设置日志记录规则，比如说不记录 open 系统调用的使用情况等。关于 proc 文件系统得使用细节，请查阅参考资料 7。

### D: 使用虚拟文件系统

有些内核开发者认为利用 ioctl（）系统调用往往会似的系统调用意义不明确，而且难控制。而将信息放入到 proc 文件系统中会使信息组织混乱，因此也不赞成过多使用。他们建议实现一种孤立的虚拟文件系统来代替 ioctl()和/proc，因为文件系统接口清楚，而且便于用户空间访问，同时利用虚拟文件系统使得利用脚本执行系统管理任务更家方便、有效。

我们举例来说如何通过虚拟文件系统修改内核信息。我们可以实现一个名为 sagafs 的虚拟文件系统，其中文件 log 对应内核存储的系统调用日志。我们可以通过文件访问特普遍方法获得日志信息：如

```shell
# cat /sagafs/log
```

使用虚拟文件系统——VFS 实现信息交互使得系统管理更加方便、清晰。但有些编程者也许会说 VFS 的 API 接口复杂不容易掌握，不要担心 2.5 内核开始就提供了一种叫做 libfs 的例程序帮助不熟悉文件系统的用户封装了实现 VFS 的通用操作。有关利用 VFS 实现交互的方法看参考资料。

### E: 使用内存映像

    Linux通过内存映像机制来提供用户程序对内存直接访问的能力。内存映像的意思是把内核中特定部分的内存空间映射到用户级程序的内存空间去。也就是说，用户空间和内核空间共享一块相同的内存。这样做的直观效果显而易见：内核在这块地址内存储变更的任何数据，用户可以立即发现和使用，根本无须数据拷贝。而在使用系统调用交互信息时，在整个操作过程中必须有一步数据拷贝的工作——或者是把内核数据拷贝到用户缓冲区，或只是把用户数据拷贝到内核缓冲区——这对于许多数据传输量大、时间要求高的应用，这无疑是致命的一击：许多应用根本就无法忍受数据拷贝所耗费的时间和资源。

我们曾经为一块高速采样设备开发过驱动程序，该设备要求在 20 兆采样率下以 1KHz 的重复频率进行 16 位实时采样，每毫秒需要采样、DMA 和处理的数据量惊人，如果要使用数据拷贝的方法，根本无法达成要求。此时，内存映像成为唯一的选择：我们在内存中保留了一块空间，将其配置成环形队列供采样设备 DMA 输出数据。再把这块内存空间映射到在用户空间运行的数据处理程序上，于是，采样设备刚刚得到并传送到主机上的数据，马上就可以被用户空间的程序处理。

实际上，内存影射方式通常也正是应用在那些内核和用户空间需要快速大量交互数据的情况下，特别是那些对实时性要求较强的应用。X window 系统的服务器的虚拟内存区域，就可以被看做是内存映像用法的一个典型例子：X 服务器需要对视频内存进行大量的数据交换，相对于 lseek/write 来说，将图形显示内存直接影射到用户空间可以显著提高效能。

并不是任何类型的应用都适合 mmap，比如像串口和鼠标这些基于流数据的字符设备，mmap 就没有太大的用武之地。并且，这种共享内存的方式存在不好同步的问题。由于没有专门的同步机制可以让用户程序和内核程序共享，所以在读取和写入数据时要有非常谨慎的设计以保证不会产生干绕。

mmap 完全是基于共享内存的观念了，也正因为此，它能提供额外的便利，但也特别难以控制。

## 内核主动发起的信息交互

### 从内核空间调用用户程序

    即使在内核中，我们有时也需要执行一些在用户级才提供的操作：如打开某个文件以读取特定数据，执行某个用户程序从而完成某个功能。因为许多数据和功能在用户空间是现有的或者已经被实现了，那么没有必要耗费大量的资源去重复。此外，内核在设计时，为了拥有更好的弹性或者性能以支持未知但有可能发生的变化，本身就要求使用用户空间的资源来配合完成任务。比如内核中动态加载模块的部分需要调用kmod。但在编译kmod的时候不可能把所有的内核模块都订下来（要是这样的话动态加载模块就没有存在意义了），所以它不可能知道在它以后才出现的那些模块的位置和加载方法。因此，模块的动态加载就采用了如下策略：加载任务实际上由位于用户空间的modprobe程序帮助完成——最简单的情形是modprobe用内核传过来的模块名字作为参数调用insmod。用这种方法来加载所需要的模块。

内核中启动用户程序还是要通过 execve 这个系统调用原形，只是此时的调用发生在内核空间，而一般的系统调用则在用户空间进行。如果系统调用带参数，那将会碰到一个问题：因为在系统调用的具体实现代码中要检查参数合法性，该检查要求所有的参数必须位于用户空间——地址处于 0x0000000——0xC0000000 之间，所以如果我们从内核传递参数（地址大于 0xC0000000）,那么检查就会拒绝我们的调用请求。为了解决这个问题，我们可以利用 set_fs 宏来修改检查策略，使得允许参数地址为内核地址。这样内核就可以直接使用该系统调用了。

例如：在 kmod 通过调用 execve 来执行 modprobe 的代码前需要有 set_fs(KERNEL_DS):

......

set_fs(KERNEL_DS);

/_ Go, go, go... _/
if (execve(program_path, argv, envp) < 0)
return -errno;
上述代码中 program_path 为"/sbin/modprobe"，argv 为{ modprobe_path, "-s", "-k", "--", (char\*)module_name, NULL }，envp 为{ "HOME=/", "TERM=linux", "PATH=/sbin:/usr/sbin:/bin:/usr/bin", NULL }。

从内核中打开文件同样使用带参数的 open 系统调用，所需的仍是要先调用 set_fs 宏。

### B 利用 brk 系统调用来导出内核数据

内核和用户空间传递数据主要是用 get_user(ptr)和 put_user(datum,ptr)例程。所以在大部分需要传递数据的系统调用中都可以找到它们的身影。可是，如果我们不是通过用户程序发起的系统调用——也就是说，没有明确的提供用户空间内的缓冲区位置——的情况下，如何向用户空间传递内核数据呢？

显然，我们不能再直接使用 put_user()了，因为我们没有办法给它指定目的缓冲区。所以，我们要借用 brk 系统调用和当前进程空间：brk 用于给进程设置堆空间的大小。每个进程拥有一个独立的堆空间，malloc 等动态内存分配函数其实就是进程的堆空间中获取内存的。我们将利用 brk 在当前进程(current process)的堆空间上扩展一块新的临时缓冲区，再用 put_user 将内核数据导出到这个确定的用户空间去。

还记得刚才我们在内核中调用用户程序的过程吗？在那里，我们有一个跳过参数检查的操作，现在有了这种方法，可以另辟蹊径了：我们在当前进程的堆上扩展一块空间，把系统调用要用到的参数通过 put_user()拷贝到新扩展得到的用户空间里，然后在调用 execve 的时候以这个新开辟空间地址作为参数，于是，参数检查的障碍不复存在了。

char \* program_path = "/bin/ls" ;

/_ 找到当前堆顶的位置_/
mmm=current->mm->brk;
/_ 用 brk 在堆顶上原扩展出一块 256 字节的新缓冲区_/
ret = brk(_(void)(mmm+256));
/_ 把 execve 需要用到的参数拷贝到新缓冲区上去*/
put_user((void*)2,program_path,strlen(program_path)+1);
/_ 成功执行/bin/ls 程序！_/
execve((char*)(mmm+2));
/* 恢复现场*/
tmp = brk((void*)mmm);

这种方法没有一般性（具体的说，这种方法有负面效应吗），只能作为一种技巧，但我们不难发现：如果你熟悉内核结构，就可以做到很多意想不到的事情！

### C: 使用信号：

    信号在内核里的用途主要集中在通知用户程序出现重大错误，强行杀死当前进程，这时内核通过发送SIGKILL信号通知进程终止，内核发送信号使用send_sign(pid,sig)例程，可以看到信号发送必须要事先知道进程序号（pid），所以要想从内核中通过发信号的方式异步通知用户进程执行某项任务，那么必须事先知道用户进程的进程号才可。而内核运行时搜索到特定进程的进程号是个费事的工作，可能要遍历整个进程控制块链表。所以用信号通知特定用户进程的方法很糟糕，一般在内核不会使用。内核中使用信号的情形只出现在通知当前进程（可以从current变量中方便获得pid）做某些通用操作，如终止操作等。因此对内核开发者该方法用处不大。类似情况还有消息操作。这里不罗嗦了。

总结 由用户级程序主动发起的信息交互，无论是采用标准的调用方式还是透过驱动程序界面，一般都要用到系统调用。而由内核主动发起信息交互的情况不多。也没有标准的界面，操作大不方便。所以一般情况下，尽可能用本文描述的前几种方法进行信息交互。毕竟，在设计的根源上，相对于客户级程序，内核就被定义为一个被动的服务提供者。因此，我们自己的开发也应该尽量遵循这种设计原则。
